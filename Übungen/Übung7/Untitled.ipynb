{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task is to implement a 10-armed bandit problem and use reinforcement learning, to solve it\n",
    "# Therefore we have n = 10 possible actions with a mean reward of Q*(a) drawn from a normal distribution Gauss(0,1)\n",
    "# The actual reward of an action a is drawn from the distribution Gauss(Q*(a), 1)\n",
    "\n",
    "# The algorithm is set to perform 1000 plays.\n",
    "# These plays get repeated 2000 times and the results get averaged.\n",
    "# The experiment should be run with epsilons of 0.1, 0.01 and 0.009\n",
    "# Furthermore the average number of times that the optinal action was selected should be plotted\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda():\n",
    "    mean = np.random.normal()\n",
    "    print(mean)\n",
    "    return lambda : np.random.normal(mean)\n",
    "\n",
    "def initialize_bandit(number_of_arms):\n",
    "    actions = [get_lambda() for i in range(number_of_arms)]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6280640320832023\n",
      "0.7750180044403907\n",
      "2.1150021778629577\n",
      "1.5470213855481731\n",
      "0.9120740886427431\n",
      "0.5029274911782863\n",
      "0.6655175245464807\n",
      "0.49910145264702793\n",
      "-1.262259938891504\n",
      "0.5114333454823011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.6185543715314937,\n",
       " 0.777651490199546,\n",
       " 2.0826528908812016,\n",
       " 1.5467261094912934,\n",
       " 0.9181973294174411,\n",
       " 0.4973147046933743,\n",
       " 0.6785826872486319,\n",
       " 0.4905456838936361,\n",
       " -1.2712134932448516,\n",
       " 0.5273007946916204]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to see if distributions draw correctly\n",
    "ac = initialize_bandit(10)\n",
    "list(map(lambda y: y(),ac))\n",
    "\n",
    "ls = [list(map(lambda y: y(),ac)) for i in range(10000)]\n",
    "list(map(lambda x: np.mean(x), list(zip(*ls))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorith as described by exercise sheet\n",
    "\n",
    "def a_simple_bandit_algo(arms, epsilon):\n",
    "    number_of_arms = len(arms)\n",
    "    Q_vec = np.array([0.0 for i in range(number_of_arms)])\n",
    "    N_vec = np.array([0.0 for i in range(number_of_arms)])\n",
    "    reward = 0\n",
    "    reward_vec = []\n",
    "    for i in range(1000):\n",
    "        if epsilon > random.random():\n",
    "            arm_num = np.argmax(Q_vec)\n",
    "            new_reward = arms[arm_num]()\n",
    "            reward += new_reward\n",
    "            reward_vec.append(reward)\n",
    "            N_vec[arm_num] = N_vec[arm_num] + 1\n",
    "            Q_vec[arm_num] = Q_vec[arm_num] + (1/N_vec[arm_num])*(new_reward-Q_vec[arm_num])\n",
    "        else:\n",
    "            arm_num = random.randint(0, number_of_arms-1)\n",
    "            new_reward = arms[arm_num]()\n",
    "            reward += new_reward\n",
    "            reward_vec.append(reward)\n",
    "            N_vec[arm_num] = N_vec[arm_num] + 1\n",
    "            Q_vec[arm_num] = Q_vec[arm_num] + (1/N_vec[arm_num])*(new_reward-Q_vec[arm_num])\n",
    "    return (Q_vec, N_vec, reward_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns expected rewards for actions, number of times action got taken and the rewards over 1000 playes averaged over 2000 samples\n",
    "def test_for_epsilon(bandits, number_of_arms, epsilon):\n",
    "    \n",
    "    Q_vec = np.array([0 for i in range(number_of_arms)])\n",
    "    N_vec = np.array([0 for i in range(number_of_arms)])\n",
    "    reward = np.array([0.0 for i in range(1000)])\n",
    "    for i in range(2000):\n",
    "        Q,N,R = a_simple_bandit_algo(bandits, epsilon)\n",
    "        Q_vec = Q_vec + Q\n",
    "        N_vec = N_vec + N\n",
    "        reward += np.array(R)\n",
    "    Q_vec = list(map(lambda x: x/1000.0, Q_vec))\n",
    "    N_vec = list(map(lambda x: x/1000.0, N_vec))\n",
    "    reward = list(map(lambda x: x/1000.0, reward))\n",
    "    return (Q_vec,N_vec,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0857618619404144\n",
      "0.5381166414055172\n",
      "0.9993809717704768\n",
      "-0.16751084095923807\n",
      "0.48006802669114634\n",
      "-0.4658682233086033\n",
      "0.7979937955582801\n",
      "0.5374251282016688\n",
      "-1.0641870292795732\n",
      "0.46864039869782353\n"
     ]
    }
   ],
   "source": [
    "#Test same bandits for three different epsilon\n",
    "\n",
    "bandits = initialize_bandit(10)\n",
    "\n",
    "Sample1 = test_for_epsilon(bandits, 10, 0.1)\n",
    "Sample2 = test_for_epsilon(bandits, 10, 0.01)\n",
    "Sample3 = test_for_epsilon(bandits, 10, 0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
